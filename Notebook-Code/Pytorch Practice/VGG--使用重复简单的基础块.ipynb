{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG\n",
    "Visual Geometry Group实验室。\n",
    "\n",
    "## VGG块\n",
    "连续使用数个相同的padding为1，size为3 * 3的卷积层，后接上stride为2，size为2 * 2的最大池化层。\n",
    "\n",
    "卷积层保持输入的高和宽不变，而池化层对其减半。\n",
    "\n",
    "## 为何选择小卷积核？\n",
    "对于给定（保证相同）感受野，采用堆积的小卷积核优于采用大的卷积核，因此可以加深网络深度保证学习更复杂的模式，代价还比较小。\n",
    "\n",
    "VGG中3个3 * 3卷积核代替7 * 7卷积核，2个3 * 3卷积核代替5 * 5卷积核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    blk = []\n",
    "    for i in range(num_convs):\n",
    "        if i == 0:\n",
    "            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        else:\n",
    "            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1))\n",
    "        blk.append(nn.ReLU())\n",
    "    # 这里会使宽高减半\n",
    "    blk.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*blk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_arch = ((1,1,64),(1,64,128),(2,128,256),(2,256,512),(2,512,512))\n",
    "# 经过5个vgg_block，宽高会减半5次，变成 224 / 32 = 7\n",
    "fc_features = 512 * 7 * 7\n",
    "fc_hidden_units = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch, fc_features, fc_hidden_units=4096, net=nn.Sequential()):\n",
    "    for i, (num_convs,  in_channels, out_channels) in enumerate(conv_arch):\n",
    "        net.add_module('vgg_block_' + str(i+1), vgg_block(num_convs, in_channels, out_channels))\n",
    "    net.add_module('fc', nn.Sequential(\n",
    "        d2l.FlattenLayer(),\n",
    "        nn.Linear(fc_features, fc_hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(fc_hidden_units, fc_hidden_units),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(fc_hidden_units, 10)\n",
    "    ))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg_block_1 output shape:  torch.Size([1, 64, 112, 112])\n",
      "vgg_block_2 output shape:  torch.Size([1, 128, 56, 56])\n",
      "vgg_block_3 output shape:  torch.Size([1, 256, 28, 28])\n",
      "vgg_block_4 output shape:  torch.Size([1, 512, 14, 14])\n",
      "vgg_block_5 output shape:  torch.Size([1, 512, 7, 7])\n",
      "fc output shape:  torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "net = vgg(conv_arch, fc_features, fc_hidden_units)\n",
    "X = torch.rand(1, 1, 224, 224)\n",
    "\n",
    "# 获取子模块和一级子模块的名字，named_modules会返回所有子模块，包括子模块的名字\n",
    "for name, blk in net.named_children():\n",
    "    X = blk(X)\n",
    "    print(name, 'output shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据获取和训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (vgg_block_1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_2): Sequential(\n",
      "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_3): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_4): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (vgg_block_5): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): FlattenLayer()\n",
      "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ratio = 8\n",
    "small_conv_arch = [(1, 1, 64 // ratio), (1, 64 // ratio, 128 // ratio), (2, 128 // ratio, 256 // ratio), (2, 256 // ratio, 512 // ratio), (2, 512 // ratio, 512 // ratio)]\n",
    "net = vgg(small_conv_arch, fc_features // ratio, fc_hidden_units // ratio)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "root = '~/Datasets'\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist2(batch_size, resize=224, root=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cpu\n",
      "epoch  1, loss  2.2998, train acc  0.094, test acc  0.100, time  156.0 sec\n",
      "epoch  1, loss  2.3036, train acc  0.078, test acc  0.100, time  307.0 sec\n",
      "epoch  1, loss  2.3048, train acc  0.078, test acc  0.100, time  444.5 sec\n",
      "epoch  1, loss  2.3028, train acc  0.078, test acc  0.100, time  585.6 sec\n",
      "epoch  1, loss  2.3004, train acc  0.097, test acc  0.100, time  722.5 sec\n",
      "epoch  1, loss  2.3032, train acc  0.091, test acc  0.100, time  860.7 sec\n",
      "epoch  1, loss  2.3037, train acc  0.094, test acc  0.100, time  998.3 sec\n",
      "epoch  1, loss  2.3039, train acc  0.096, test acc  0.100, time  1136.1 sec\n",
      "epoch  1, loss  2.3048, train acc  0.094, test acc  0.100, time  1273.8 sec\n",
      "epoch  1, loss  2.3052, train acc  0.094, test acc  0.100, time  1412.7 sec\n",
      "epoch  1, loss  2.3054, train acc  0.095, test acc  0.100, time  1552.1 sec\n",
      "epoch  1, loss  2.3053, train acc  0.098, test acc  0.100, time  1689.2 sec\n",
      "epoch  1, loss  2.3042, train acc  0.097, test acc  0.100, time  1827.8 sec\n",
      "epoch  1, loss  2.3047, train acc  0.098, test acc  0.100, time  1967.7 sec\n",
      "epoch  1, loss  2.3051, train acc  0.094, test acc  0.100, time  2107.8 sec\n",
      "epoch  1, loss  2.3051, train acc  0.095, test acc  0.100, time  2244.9 sec\n",
      "epoch  1, loss  2.3051, train acc  0.093, test acc  0.100, time  2382.3 sec\n",
      "epoch  1, loss  2.3044, train acc  0.098, test acc  0.100, time  2533.2 sec\n",
      "epoch  1, loss  2.3044, train acc  0.096, test acc  0.100, time  2683.7 sec\n",
      "epoch  1, loss  2.3046, train acc  0.096, test acc  0.100, time  2832.6 sec\n",
      "epoch  1, loss  2.3044, train acc  0.097, test acc  0.100, time  3007.3 sec\n",
      "epoch  1, loss  2.3042, train acc  0.098, test acc  0.100, time  3155.8 sec\n",
      "epoch  1, loss  2.3042, train acc  0.099, test acc  0.100, time  3308.7 sec\n",
      "epoch  1, loss  2.3043, train acc  0.098, test acc  0.100, time  3449.9 sec\n",
      "epoch  1, loss  2.3042, train acc  0.098, test acc  0.100, time  3589.0 sec\n",
      "epoch  1, loss  2.3041, train acc  0.100, test acc  0.100, time  3736.4 sec\n",
      "epoch  1, loss  2.3040, train acc  0.099, test acc  0.100, time  3876.2 sec\n",
      "epoch  1, loss  2.3041, train acc  0.098, test acc  0.100, time  4020.2 sec\n",
      "epoch  1, loss  2.3040, train acc  0.097, test acc  0.100, time  4165.8 sec\n",
      "epoch  1, loss  2.3039, train acc  0.097, test acc  0.100, time  4312.3 sec\n",
      "epoch  1, loss  2.3039, train acc  0.096, test acc  0.100, time  4503.8 sec\n",
      "epoch  1, loss  2.3040, train acc  0.096, test acc  0.100, time  4651.5 sec\n",
      "epoch  1, loss  2.3038, train acc  0.098, test acc  0.100, time  4802.3 sec\n",
      "epoch  1, loss  2.3038, train acc  0.098, test acc  0.100, time  4959.5 sec\n",
      "epoch  1, loss  2.3039, train acc  0.097, test acc  0.100, time  5106.7 sec\n",
      "epoch  1, loss  2.3039, train acc  0.098, test acc  0.100, time  5262.0 sec\n",
      "epoch  1, loss  2.3040, train acc  0.098, test acc  0.100, time  5404.5 sec\n",
      "epoch  1, loss  2.3037, train acc  0.099, test acc  0.100, time  5545.0 sec\n",
      "epoch  1, loss  2.3035, train acc  0.100, test acc  0.100, time  5685.5 sec\n",
      "epoch  1, loss  2.3036, train acc  0.101, test acc  0.100, time  5826.6 sec\n",
      "epoch  1, loss  2.3035, train acc  0.100, test acc  0.100, time  5965.5 sec\n",
      "epoch  1, loss  2.3036, train acc  0.099, test acc  0.100, time  6107.6 sec\n",
      "epoch  1, loss  2.3034, train acc  0.101, test acc  0.100, time  6256.0 sec\n",
      "epoch  1, loss  2.3035, train acc  0.099, test acc  0.100, time  6421.6 sec\n",
      "epoch  1, loss  2.3036, train acc  0.099, test acc  0.100, time  6563.2 sec\n",
      "epoch  1, loss  2.3036, train acc  0.098, test acc  0.100, time  6701.3 sec\n",
      "epoch  1, loss  2.3035, train acc  0.100, test acc  0.100, time  6842.8 sec\n",
      "epoch  1, loss  2.3034, train acc  0.100, test acc  0.100, time  6979.5 sec\n",
      "epoch  1, loss  2.3032, train acc  0.101, test acc  0.100, time  7137.1 sec\n",
      "epoch  1, loss  2.3029, train acc  0.103, test acc  0.100, time  7282.6 sec\n",
      "epoch  1, loss  2.3030, train acc  0.103, test acc  0.100, time  7433.0 sec\n",
      "epoch  1, loss  2.3029, train acc  0.102, test acc  0.100, time  7601.2 sec\n",
      "epoch  1, loss  2.3028, train acc  0.103, test acc  0.100, time  7749.1 sec\n",
      "epoch  1, loss  2.3028, train acc  0.102, test acc  0.100, time  7895.4 sec\n",
      "epoch  1, loss  2.3027, train acc  0.103, test acc  0.100, time  8046.2 sec\n",
      "epoch  1, loss  2.3026, train acc  0.104, test acc  0.100, time  8193.1 sec\n",
      "epoch  1, loss  2.3026, train acc  0.104, test acc  0.100, time  8342.7 sec\n",
      "epoch  1, loss  2.3025, train acc  0.105, test acc  0.100, time  8484.6 sec\n",
      "epoch  1, loss  2.3026, train acc  0.104, test acc  0.100, time  8622.8 sec\n",
      "epoch  1, loss  2.3026, train acc  0.103, test acc  0.100, time  8762.9 sec\n",
      "epoch  1, loss  2.3027, train acc  0.103, test acc  0.100, time  8926.1 sec\n",
      "epoch  1, loss  2.3026, train acc  0.103, test acc  0.100, time  9087.5 sec\n",
      "epoch  1, loss  2.3027, train acc  0.103, test acc  0.100, time  9235.5 sec\n",
      "epoch  1, loss  2.3030, train acc  0.102, test acc  0.100, time  9380.2 sec\n",
      "epoch  1, loss  2.3029, train acc  0.103, test acc  0.100, time  9514.6 sec\n",
      "epoch  1, loss  2.3028, train acc  0.104, test acc  0.100, time  9650.1 sec\n",
      "epoch  1, loss  2.3028, train acc  0.104, test acc  0.100, time  9785.5 sec\n",
      "epoch  1, loss  2.3029, train acc  0.104, test acc  0.100, time  9922.3 sec\n",
      "epoch  1, loss  2.3030, train acc  0.103, test acc  0.100, time  10059.5 sec\n",
      "epoch  1, loss  2.3031, train acc  0.102, test acc  0.100, time  10197.5 sec\n",
      "epoch  1, loss  2.3032, train acc  0.102, test acc  0.100, time  10332.4 sec\n",
      "epoch  1, loss  2.3032, train acc  0.102, test acc  0.100, time  10466.9 sec\n",
      "epoch  1, loss  2.3033, train acc  0.102, test acc  0.100, time  10601.2 sec\n",
      "epoch  1, loss  2.3034, train acc  0.102, test acc  0.100, time  10737.2 sec\n",
      "epoch  1, loss  2.3034, train acc  0.101, test acc  0.100, time  10871.8 sec\n",
      "epoch  1, loss  2.3034, train acc  0.101, test acc  0.100, time  11005.8 sec\n",
      "epoch  1, loss  2.3034, train acc  0.101, test acc  0.100, time  11141.0 sec\n",
      "epoch  1, loss  2.3034, train acc  0.102, test acc  0.100, time  11350.4 sec\n",
      "epoch  1, loss  2.3034, train acc  0.101, test acc  0.100, time  11543.4 sec\n",
      "epoch  1, loss  2.3034, train acc  0.102, test acc  0.100, time  11730.5 sec\n",
      "epoch  1, loss  2.3035, train acc  0.101, test acc  0.100, time  11917.5 sec\n",
      "epoch  1, loss  2.3034, train acc  0.101, test acc  0.100, time  12101.6 sec\n",
      "epoch  1, loss  2.3034, train acc  0.101, test acc  0.100, time  12292.0 sec\n",
      "epoch  1, loss  2.3035, train acc  0.101, test acc  0.100, time  12469.8 sec\n",
      "epoch  1, loss  2.3034, train acc  0.101, test acc  0.100, time  12650.1 sec\n",
      "epoch  1, loss  2.3034, train acc  0.101, test acc  0.100, time  12811.4 sec\n",
      "epoch  1, loss  2.3034, train acc  0.101, test acc  0.100, time  12970.9 sec\n",
      "epoch  1, loss  2.3034, train acc  0.101, test acc  0.100, time  13131.2 sec\n",
      "epoch  1, loss  2.3033, train acc  0.101, test acc  0.100, time  13276.9 sec\n",
      "epoch  1, loss  2.3032, train acc  0.102, test acc  0.100, time  13450.1 sec\n",
      "epoch  1, loss  2.3032, train acc  0.103, test acc  0.174, time  13619.5 sec\n",
      "epoch  1, loss  2.3032, train acc  0.103, test acc  0.195, time  13761.4 sec\n",
      "epoch  1, loss  2.3033, train acc  0.102, test acc  0.198, time  13896.2 sec\n",
      "epoch  1, loss  2.3031, train acc  0.102, test acc  0.205, time  14030.6 sec\n",
      "epoch  1, loss  2.3028, train acc  0.103, test acc  0.216, time  14165.7 sec\n",
      "epoch  1, loss  2.3020, train acc  0.104, test acc  0.225, time  14301.0 sec\n",
      "epoch  1, loss  2.2997, train acc  0.105, test acc  0.139, time  14436.1 sec\n",
      "epoch  1, loss  2.2970, train acc  0.106, test acc  0.250, time  14571.7 sec\n",
      "epoch  1, loss  2.2946, train acc  0.108, test acc  0.311, time  14707.0 sec\n",
      "epoch  1, loss  2.2913, train acc  0.110, test acc  0.180, time  14842.9 sec\n",
      "epoch  1, loss  2.2886, train acc  0.110, test acc  0.363, time  14977.8 sec\n",
      "epoch  1, loss  2.2818, train acc  0.113, test acc  0.408, time  15122.1 sec\n",
      "epoch  1, loss  2.2756, train acc  0.116, test acc  0.428, time  15261.2 sec\n",
      "epoch  1, loss  2.2691, train acc  0.119, test acc  0.422, time  15406.0 sec\n",
      "epoch  1, loss  2.2613, train acc  0.121, test acc  0.443, time  15543.6 sec\n",
      "epoch  1, loss  2.2550, train acc  0.124, test acc  0.396, time  15676.8 sec\n",
      "epoch  1, loss  2.2497, train acc  0.127, test acc  0.441, time  15810.4 sec\n",
      "epoch  1, loss  2.2440, train acc  0.129, test acc  0.500, time  15970.7 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1, loss  2.2369, train acc  0.132, test acc  0.530, time  16117.0 sec\n",
      "epoch  1, loss  2.2294, train acc  0.135, test acc  0.510, time  16256.5 sec\n",
      "epoch  1, loss  2.2202, train acc  0.138, test acc  0.492, time  16405.8 sec\n",
      "epoch  1, loss  2.2121, train acc  0.140, test acc  0.493, time  16562.2 sec\n",
      "epoch  1, loss  2.2017, train acc  0.145, test acc  0.489, time  16718.3 sec\n",
      "epoch  1, loss  2.1951, train acc  0.148, test acc  0.519, time  16861.0 sec\n",
      "epoch  1, loss  2.1900, train acc  0.149, test acc  0.536, time  17001.2 sec\n",
      "epoch  1, loss  2.1834, train acc  0.152, test acc  0.558, time  17142.6 sec\n",
      "epoch  1, loss  2.1756, train acc  0.155, test acc  0.519, time  17286.3 sec\n",
      "epoch  1, loss  2.1693, train acc  0.157, test acc  0.528, time  17430.9 sec\n",
      "epoch  1, loss  2.1599, train acc  0.161, test acc  0.522, time  17572.2 sec\n",
      "epoch  1, loss  2.1514, train acc  0.164, test acc  0.530, time  17740.7 sec\n",
      "epoch  1, loss  2.1418, train acc  0.167, test acc  0.533, time  17885.7 sec\n",
      "epoch  1, loss  2.1348, train acc  0.169, test acc  0.530, time  18045.6 sec\n",
      "epoch  1, loss  2.1281, train acc  0.171, test acc  0.525, time  18204.4 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1c2a5ef7eb2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_cuda_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/ML/Machine-Learning/Notebook-Code/Pytorch Practice/d2lzh_pytorch.py\u001b[0m in \u001b[0;36mtrain_cuda_cpu\u001b[0;34m(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mbatch_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             print('epoch % d, loss % .4f, train acc % .3f, test acc % .3f, time % .1f sec' % (\n\u001b[1;32m    230\u001b[0m                 epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n",
      "\u001b[0;32m~/Documents/ML/Machine-Learning/Notebook-Code/Pytorch Practice/d2lzh_pytorch.py\u001b[0m in \u001b[0;36mevaluate_accuracy\u001b[0;34m(data_iter, net, device)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# 评估模式，会关闭dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0macc_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0;31m# 改回训练模式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_cuda_cpu(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
