{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 相邻像素在像素中可能举例较远，难以被模型识别\n",
    "2. 对于大尺寸图像，全连接层容易造成模型过大，权重参数过多，消耗资源较多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet模型\n",
    "\n",
    "分为卷积层块和全连接层块两个部分。\n",
    "\n",
    "## 卷积层块\n",
    "卷积层块里的基本单位是**卷积层** 后接 **池化层**，前者用来识别图像里的空间模式，后者用来降低卷积层对位置的敏感性。\n",
    "\n",
    "卷积层：5 * 5的窗口，输出接sigmoid激活函数。第一层输出通道为6，第二层输出通道数则增加到16，增加输出通道的目的是使得两层的参数尺寸类似。\n",
    "\n",
    "池化层：窗口形状为 2 * 2，步幅为2，这样池化窗口每次覆盖的区域互不重叠。\n",
    "\n",
    "卷积层块输出形状：（批量大小，通道，高，宽）\n",
    "\n",
    "\n",
    "## 全连接层块\n",
    "当卷积层块的输出传入全连接层块时，全连接层块会将小批量中每个样本变平（flatten）。\n",
    "\n",
    "全连接层块含3个全连接层，它们输出个数分别是120、84、10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import d2lzh_pytorch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5), # in_channel, out_channels, kernel_size \n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16 * 4 * 4, 120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        # -1 表示除了将batch_size的留住，其他都平铺\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): Sigmoid()\n",
      "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cpu\n",
      "epoch  1, loss  2.3478, train acc  0.094, test acc  0.100, time  2.3 sec\n",
      "epoch  1, loss  2.3300, train acc  0.100, test acc  0.100, time  4.9 sec\n",
      "epoch  1, loss  2.3212, train acc  0.096, test acc  0.100, time  7.3 sec\n",
      "epoch  1, loss  2.3149, train acc  0.101, test acc  0.100, time  9.6 sec\n",
      "epoch  1, loss  2.3120, train acc  0.095, test acc  0.100, time  12.2 sec\n",
      "epoch  1, loss  2.3113, train acc  0.096, test acc  0.100, time  14.4 sec\n",
      "epoch  1, loss  2.3098, train acc  0.098, test acc  0.100, time  16.3 sec\n",
      "epoch  1, loss  2.3092, train acc  0.099, test acc  0.100, time  18.3 sec\n",
      "epoch  1, loss  2.3093, train acc  0.097, test acc  0.100, time  20.5 sec\n",
      "epoch  1, loss  2.3094, train acc  0.096, test acc  0.100, time  22.8 sec\n",
      "epoch  1, loss  2.3097, train acc  0.096, test acc  0.100, time  24.9 sec\n",
      "epoch  1, loss  2.3089, train acc  0.097, test acc  0.100, time  26.9 sec\n",
      "epoch  1, loss  2.3084, train acc  0.099, test acc  0.100, time  28.8 sec\n",
      "epoch  1, loss  2.3089, train acc  0.098, test acc  0.100, time  31.1 sec\n",
      "epoch  1, loss  2.3095, train acc  0.099, test acc  0.100, time  35.1 sec\n",
      "epoch  1, loss  2.3103, train acc  0.098, test acc  0.100, time  37.4 sec\n",
      "epoch  1, loss  2.3099, train acc  0.098, test acc  0.100, time  39.3 sec\n",
      "epoch  1, loss  2.3102, train acc  0.098, test acc  0.100, time  41.4 sec\n",
      "epoch  1, loss  2.3102, train acc  0.100, test acc  0.100, time  44.4 sec\n",
      "epoch  1, loss  2.3097, train acc  0.100, test acc  0.100, time  46.9 sec\n",
      "epoch  1, loss  2.3097, train acc  0.099, test acc  0.100, time  49.5 sec\n",
      "epoch  1, loss  2.3095, train acc  0.100, test acc  0.100, time  53.6 sec\n",
      "epoch  1, loss  2.3097, train acc  0.099, test acc  0.100, time  55.7 sec\n",
      "epoch  1, loss  2.3096, train acc  0.098, test acc  0.100, time  57.6 sec\n",
      "epoch  1, loss  2.3094, train acc  0.098, test acc  0.100, time  59.5 sec\n",
      "epoch  1, loss  2.3094, train acc  0.098, test acc  0.100, time  61.5 sec\n",
      "epoch  1, loss  2.3093, train acc  0.098, test acc  0.100, time  63.4 sec\n",
      "epoch  1, loss  2.3093, train acc  0.097, test acc  0.100, time  65.9 sec\n",
      "epoch  1, loss  2.3090, train acc  0.097, test acc  0.100, time  68.0 sec\n",
      "epoch  1, loss  2.3090, train acc  0.097, test acc  0.100, time  69.9 sec\n",
      "epoch  1, loss  2.3088, train acc  0.097, test acc  0.100, time  71.8 sec\n",
      "epoch  1, loss  2.3085, train acc  0.097, test acc  0.100, time  73.6 sec\n",
      "epoch  1, loss  2.3083, train acc  0.098, test acc  0.100, time  75.5 sec\n",
      "epoch  1, loss  2.3081, train acc  0.098, test acc  0.100, time  77.4 sec\n",
      "epoch  1, loss  2.3082, train acc  0.098, test acc  0.100, time  79.2 sec\n",
      "epoch  1, loss  2.3080, train acc  0.098, test acc  0.100, time  81.1 sec\n",
      "epoch  1, loss  2.3078, train acc  0.098, test acc  0.100, time  82.9 sec\n",
      "epoch  1, loss  2.3078, train acc  0.098, test acc  0.100, time  84.8 sec\n",
      "epoch  1, loss  2.3079, train acc  0.097, test acc  0.100, time  86.7 sec\n",
      "epoch  1, loss  2.3080, train acc  0.097, test acc  0.100, time  88.6 sec\n",
      "epoch  1, loss  2.3079, train acc  0.097, test acc  0.100, time  90.4 sec\n",
      "epoch  1, loss  2.3076, train acc  0.097, test acc  0.100, time  92.3 sec\n",
      "epoch  1, loss  2.3076, train acc  0.097, test acc  0.100, time  94.2 sec\n",
      "epoch  1, loss  2.3074, train acc  0.098, test acc  0.100, time  96.1 sec\n",
      "epoch  1, loss  2.3074, train acc  0.098, test acc  0.100, time  98.4 sec\n",
      "epoch  1, loss  2.3072, train acc  0.098, test acc  0.100, time  100.5 sec\n",
      "epoch  1, loss  2.3071, train acc  0.098, test acc  0.100, time  102.6 sec\n",
      "epoch  1, loss  2.3071, train acc  0.098, test acc  0.100, time  104.7 sec\n",
      "epoch  1, loss  2.3072, train acc  0.099, test acc  0.100, time  106.6 sec\n",
      "epoch  1, loss  2.3072, train acc  0.098, test acc  0.100, time  109.1 sec\n",
      "epoch  1, loss  2.3072, train acc  0.098, test acc  0.100, time  111.3 sec\n",
      "epoch  1, loss  2.3072, train acc  0.098, test acc  0.100, time  113.1 sec\n",
      "epoch  1, loss  2.3070, train acc  0.098, test acc  0.100, time  115.0 sec\n",
      "epoch  1, loss  2.3070, train acc  0.098, test acc  0.102, time  117.1 sec\n",
      "epoch  1, loss  2.3069, train acc  0.098, test acc  0.100, time  119.0 sec\n",
      "epoch  1, loss  2.3067, train acc  0.099, test acc  0.100, time  120.9 sec\n",
      "epoch  1, loss  2.3066, train acc  0.099, test acc  0.100, time  122.7 sec\n",
      "epoch  1, loss  2.3066, train acc  0.098, test acc  0.100, time  124.6 sec\n",
      "epoch  1, loss  2.3065, train acc  0.098, test acc  0.100, time  126.9 sec\n",
      "epoch  1, loss  2.3064, train acc  0.098, test acc  0.100, time  1406.0 sec\n",
      "epoch  1, loss  2.3064, train acc  0.098, test acc  0.100, time  1408.8 sec\n",
      "epoch  1, loss  2.3064, train acc  0.098, test acc  0.100, time  1411.2 sec\n",
      "epoch  1, loss  2.3063, train acc  0.098, test acc  0.100, time  1413.4 sec\n",
      "epoch  1, loss  2.3063, train acc  0.098, test acc  0.159, time  1415.5 sec\n",
      "epoch  1, loss  2.3062, train acc  0.099, test acc  0.129, time  1417.6 sec\n",
      "epoch  1, loss  2.3061, train acc  0.099, test acc  0.100, time  1420.2 sec\n",
      "epoch  1, loss  2.3060, train acc  0.099, test acc  0.102, time  1422.2 sec\n",
      "epoch  1, loss  2.3059, train acc  0.099, test acc  0.181, time  1424.0 sec\n",
      "epoch  1, loss  2.3059, train acc  0.101, test acc  0.102, time  1425.8 sec\n",
      "epoch  1, loss  2.3058, train acc  0.100, test acc  0.100, time  1427.7 sec\n",
      "epoch  1, loss  2.3057, train acc  0.100, test acc  0.152, time  1429.5 sec\n",
      "epoch  1, loss  2.3056, train acc  0.100, test acc  0.186, time  1431.3 sec\n",
      "epoch  1, loss  2.3055, train acc  0.101, test acc  0.152, time  1433.1 sec\n",
      "epoch  1, loss  2.3054, train acc  0.102, test acc  0.142, time  1435.3 sec\n",
      "epoch  1, loss  2.3053, train acc  0.102, test acc  0.131, time  1437.4 sec\n",
      "epoch  1, loss  2.3052, train acc  0.103, test acc  0.132, time  1439.4 sec\n",
      "epoch  1, loss  2.3051, train acc  0.104, test acc  0.118, time  1442.0 sec\n",
      "epoch  1, loss  2.3050, train acc  0.104, test acc  0.132, time  1444.2 sec\n",
      "epoch  1, loss  2.3047, train acc  0.105, test acc  0.116, time  1446.2 sec\n",
      "epoch  1, loss  2.3046, train acc  0.104, test acc  0.124, time  1448.1 sec\n",
      "epoch  1, loss  2.3043, train acc  0.105, test acc  0.126, time  1450.0 sec\n",
      "epoch  1, loss  2.3042, train acc  0.105, test acc  0.133, time  1452.1 sec\n",
      "epoch  1, loss  2.3040, train acc  0.105, test acc  0.135, time  1454.1 sec\n",
      "epoch  1, loss  2.3039, train acc  0.105, test acc  0.155, time  1456.2 sec\n",
      "epoch  1, loss  2.3036, train acc  0.105, test acc  0.124, time  1458.2 sec\n",
      "epoch  1, loss  2.3032, train acc  0.106, test acc  0.144, time  1460.5 sec\n",
      "epoch  1, loss  2.3029, train acc  0.106, test acc  0.175, time  1462.3 sec\n",
      "epoch  1, loss  2.3026, train acc  0.107, test acc  0.164, time  1464.4 sec\n",
      "epoch  1, loss  2.3023, train acc  0.107, test acc  0.196, time  1466.6 sec\n",
      "epoch  1, loss  2.3019, train acc  0.108, test acc  0.261, time  1468.8 sec\n",
      "epoch  1, loss  2.3016, train acc  0.110, test acc  0.282, time  1470.7 sec\n",
      "epoch  1, loss  2.3011, train acc  0.112, test acc  0.286, time  1473.0 sec\n",
      "epoch  1, loss  2.3006, train acc  0.114, test acc  0.290, time  1475.4 sec\n",
      "epoch  1, loss  2.3002, train acc  0.116, test acc  0.287, time  1477.4 sec\n",
      "epoch  1, loss  2.2996, train acc  0.118, test acc  0.271, time  1479.9 sec\n",
      "epoch  1, loss  2.2991, train acc  0.119, test acc  0.291, time  1482.1 sec\n",
      "epoch  1, loss  2.2984, train acc  0.121, test acc  0.340, time  1484.2 sec\n",
      "epoch  1, loss  2.2977, train acc  0.123, test acc  0.381, time  1486.3 sec\n",
      "epoch  1, loss  2.2969, train acc  0.126, test acc  0.384, time  1488.4 sec\n",
      "epoch  1, loss  2.2959, train acc  0.128, test acc  0.365, time  1490.6 sec\n",
      "epoch  1, loss  2.2951, train acc  0.131, test acc  0.351, time  1492.7 sec\n",
      "epoch  1, loss  2.2941, train acc  0.132, test acc  0.343, time  1494.6 sec\n",
      "epoch  1, loss  2.2933, train acc  0.134, test acc  0.347, time  1496.6 sec\n",
      "epoch  1, loss  2.2922, train acc  0.135, test acc  0.331, time  1498.5 sec\n",
      "epoch  1, loss  2.2910, train acc  0.137, test acc  0.325, time  1500.5 sec\n",
      "epoch  1, loss  2.2897, train acc  0.139, test acc  0.324, time  1502.3 sec\n",
      "epoch  1, loss  2.2882, train acc  0.141, test acc  0.322, time  1504.2 sec\n",
      "epoch  1, loss  2.2869, train acc  0.142, test acc  0.319, time  1506.1 sec\n",
      "epoch  1, loss  2.2854, train acc  0.144, test acc  0.320, time  1508.1 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1, loss  2.2838, train acc  0.145, test acc  0.323, time  1510.1 sec\n",
      "epoch  1, loss  2.2820, train acc  0.147, test acc  0.324, time  1512.1 sec\n",
      "epoch  1, loss  2.2804, train acc  0.148, test acc  0.323, time  1514.3 sec\n",
      "epoch  1, loss  2.2784, train acc  0.150, test acc  0.326, time  1516.5 sec\n",
      "epoch  1, loss  2.2766, train acc  0.151, test acc  0.328, time  1518.4 sec\n",
      "epoch  1, loss  2.2745, train acc  0.153, test acc  0.334, time  1520.6 sec\n",
      "epoch  1, loss  2.2723, train acc  0.154, test acc  0.341, time  1522.7 sec\n",
      "epoch  1, loss  2.2700, train acc  0.156, test acc  0.357, time  1524.7 sec\n",
      "epoch  1, loss  2.2680, train acc  0.158, test acc  0.374, time  1526.7 sec\n",
      "epoch  1, loss  2.2655, train acc  0.160, test acc  0.373, time  1528.8 sec\n",
      "epoch  1, loss  2.2629, train acc  0.162, test acc  0.376, time  1531.1 sec\n",
      "epoch  1, loss  2.2605, train acc  0.164, test acc  0.377, time  1533.2 sec\n",
      "epoch  1, loss  2.2577, train acc  0.166, test acc  0.382, time  1535.3 sec\n",
      "epoch  1, loss  2.2552, train acc  0.167, test acc  0.404, time  1537.1 sec\n",
      "epoch  1, loss  2.2521, train acc  0.170, test acc  0.395, time  1539.0 sec\n",
      "epoch  1, loss  2.2497, train acc  0.171, test acc  0.391, time  1541.7 sec\n",
      "epoch  1, loss  2.2471, train acc  0.173, test acc  0.390, time  1544.0 sec\n",
      "epoch  1, loss  2.2444, train acc  0.175, test acc  0.390, time  1546.0 sec\n",
      "epoch  1, loss  2.2414, train acc  0.177, test acc  0.388, time  1548.2 sec\n",
      "epoch  1, loss  2.2382, train acc  0.178, test acc  0.387, time  1550.3 sec\n",
      "epoch  1, loss  2.2351, train acc  0.180, test acc  0.392, time  1552.1 sec\n",
      "epoch  1, loss  2.2316, train acc  0.182, test acc  0.395, time  1553.9 sec\n",
      "epoch  1, loss  2.2282, train acc  0.184, test acc  0.398, time  1555.7 sec\n",
      "epoch  1, loss  2.2250, train acc  0.185, test acc  0.400, time  1557.7 sec\n",
      "epoch  1, loss  2.2222, train acc  0.187, test acc  0.403, time  1559.8 sec\n",
      "epoch  1, loss  2.2184, train acc  0.189, test acc  0.405, time  1561.8 sec\n",
      "epoch  1, loss  2.2145, train acc  0.191, test acc  0.408, time  1563.6 sec\n",
      "epoch  1, loss  2.2112, train acc  0.193, test acc  0.413, time  1565.6 sec\n",
      "epoch  1, loss  2.2074, train acc  0.195, test acc  0.413, time  1567.4 sec\n",
      "epoch  1, loss  2.2039, train acc  0.196, test acc  0.411, time  1569.2 sec\n",
      "epoch  1, loss  2.2005, train acc  0.198, test acc  0.411, time  1571.2 sec\n",
      "epoch  1, loss  2.1969, train acc  0.199, test acc  0.413, time  1573.3 sec\n",
      "epoch  1, loss  2.1929, train acc  0.201, test acc  0.413, time  1575.5 sec\n",
      "epoch  1, loss  2.1891, train acc  0.202, test acc  0.413, time  1577.3 sec\n",
      "epoch  1, loss  2.1854, train acc  0.204, test acc  0.416, time  1579.4 sec\n",
      "epoch  1, loss  2.1817, train acc  0.205, test acc  0.420, time  1581.3 sec\n",
      "epoch  1, loss  2.1778, train acc  0.206, test acc  0.426, time  1583.1 sec\n",
      "epoch  1, loss  2.1741, train acc  0.208, test acc  0.434, time  1585.0 sec\n",
      "epoch  1, loss  2.1701, train acc  0.210, test acc  0.441, time  1586.9 sec\n",
      "epoch  1, loss  2.1663, train acc  0.211, test acc  0.448, time  1588.7 sec\n",
      "epoch  1, loss  2.1625, train acc  0.213, test acc  0.451, time  1590.6 sec\n",
      "epoch  1, loss  2.1583, train acc  0.215, test acc  0.455, time  1592.4 sec\n",
      "epoch  1, loss  2.1542, train acc  0.216, test acc  0.459, time  1594.3 sec\n",
      "epoch  1, loss  2.1503, train acc  0.218, test acc  0.467, time  1596.1 sec\n",
      "epoch  1, loss  2.1465, train acc  0.219, test acc  0.477, time  1598.0 sec\n",
      "epoch  1, loss  2.1420, train acc  0.221, test acc  0.484, time  1599.9 sec\n",
      "epoch  1, loss  2.1378, train acc  0.223, test acc  0.493, time  1601.7 sec\n",
      "epoch  1, loss  2.1339, train acc  0.225, test acc  0.494, time  1603.5 sec\n",
      "epoch  1, loss  2.1305, train acc  0.226, test acc  0.503, time  1605.3 sec\n",
      "epoch  1, loss  2.1264, train acc  0.228, test acc  0.493, time  1607.1 sec\n",
      "epoch  1, loss  2.1222, train acc  0.230, test acc  0.488, time  1608.9 sec\n",
      "epoch  1, loss  2.1182, train acc  0.231, test acc  0.486, time  1610.9 sec\n",
      "epoch  1, loss  2.1141, train acc  0.233, test acc  0.484, time  1613.1 sec\n",
      "epoch  1, loss  2.1100, train acc  0.234, test acc  0.486, time  1615.3 sec\n",
      "epoch  1, loss  2.1058, train acc  0.236, test acc  0.486, time  1617.5 sec\n",
      "epoch  1, loss  2.1016, train acc  0.237, test acc  0.489, time  1619.6 sec\n",
      "epoch  1, loss  2.0975, train acc  0.239, test acc  0.490, time  1621.8 sec\n",
      "epoch  1, loss  2.0935, train acc  0.241, test acc  0.488, time  1623.8 sec\n",
      "epoch  1, loss  2.0895, train acc  0.242, test acc  0.487, time  1625.6 sec\n",
      "epoch  1, loss  2.0859, train acc  0.243, test acc  0.484, time  1627.5 sec\n",
      "epoch  1, loss  2.0818, train acc  0.245, test acc  0.481, time  1629.6 sec\n",
      "epoch  1, loss  2.0781, train acc  0.246, test acc  0.483, time  1631.5 sec\n",
      "epoch  1, loss  2.0741, train acc  0.247, test acc  0.488, time  1633.5 sec\n",
      "epoch  1, loss  2.0703, train acc  0.249, test acc  0.493, time  1635.9 sec\n",
      "epoch  1, loss  2.0665, train acc  0.250, test acc  0.501, time  1638.1 sec\n",
      "epoch  1, loss  2.0626, train acc  0.251, test acc  0.507, time  1640.3 sec\n",
      "epoch  1, loss  2.0586, train acc  0.252, test acc  0.515, time  1642.5 sec\n",
      "epoch  1, loss  2.0545, train acc  0.254, test acc  0.522, time  1644.8 sec\n",
      "epoch  1, loss  2.0504, train acc  0.255, test acc  0.527, time  1646.9 sec\n",
      "epoch  1, loss  2.0463, train acc  0.257, test acc  0.534, time  1648.9 sec\n",
      "epoch  1, loss  2.0423, train acc  0.258, test acc  0.539, time  1651.2 sec\n",
      "epoch  1, loss  2.0384, train acc  0.260, test acc  0.529, time  1653.2 sec\n",
      "epoch  1, loss  2.0345, train acc  0.261, test acc  0.530, time  1655.2 sec\n",
      "epoch  1, loss  2.0304, train acc  0.263, test acc  0.530, time  1657.7 sec\n",
      "epoch  1, loss  2.0268, train acc  0.264, test acc  0.530, time  1659.9 sec\n",
      "epoch  1, loss  2.0232, train acc  0.265, test acc  0.532, time  1661.9 sec\n",
      "epoch  1, loss  2.0194, train acc  0.267, test acc  0.532, time  1664.0 sec\n",
      "epoch  1, loss  2.0155, train acc  0.268, test acc  0.533, time  1666.5 sec\n",
      "epoch  1, loss  2.0113, train acc  0.270, test acc  0.534, time  1668.7 sec\n",
      "epoch  1, loss  2.0077, train acc  0.271, test acc  0.536, time  1670.5 sec\n",
      "epoch  1, loss  2.0037, train acc  0.272, test acc  0.537, time  1672.4 sec\n",
      "epoch  1, loss  1.9999, train acc  0.273, test acc  0.536, time  1674.4 sec\n",
      "epoch  1, loss  1.9959, train acc  0.275, test acc  0.537, time  1676.4 sec\n",
      "epoch  1, loss  1.9921, train acc  0.276, test acc  0.539, time  1678.6 sec\n",
      "epoch  1, loss  1.9886, train acc  0.277, test acc  0.540, time  1680.7 sec\n",
      "epoch  1, loss  1.9849, train acc  0.279, test acc  0.543, time  1682.6 sec\n",
      "epoch  1, loss  1.9813, train acc  0.280, test acc  0.544, time  1684.4 sec\n",
      "epoch  1, loss  1.9775, train acc  0.281, test acc  0.550, time  1686.7 sec\n",
      "epoch  1, loss  1.9735, train acc  0.283, test acc  0.556, time  1688.9 sec\n",
      "epoch  1, loss  1.9698, train acc  0.284, test acc  0.564, time  1691.0 sec\n",
      "epoch  1, loss  1.9659, train acc  0.286, test acc  0.571, time  1693.0 sec\n",
      "epoch  1, loss  1.9621, train acc  0.287, test acc  0.573, time  1695.0 sec\n",
      "epoch  1, loss  1.9583, train acc  0.288, test acc  0.570, time  1696.8 sec\n",
      "epoch  1, loss  1.9546, train acc  0.290, test acc  0.568, time  1699.0 sec\n",
      "epoch  1, loss  1.9509, train acc  0.292, test acc  0.567, time  1701.0 sec\n",
      "epoch  1, loss  1.9474, train acc  0.293, test acc  0.565, time  1703.2 sec\n",
      "epoch  1, loss  1.9439, train acc  0.294, test acc  0.564, time  1705.3 sec\n",
      "epoch  1, loss  1.9400, train acc  0.296, test acc  0.562, time  1707.1 sec\n",
      "epoch  1, loss  1.9366, train acc  0.297, test acc  0.564, time  1709.0 sec\n",
      "epoch  1, loss  1.9329, train acc  0.298, test acc  0.567, time  1710.9 sec\n",
      "epoch  1, loss  1.9293, train acc  0.299, test acc  0.570, time  1712.8 sec\n",
      "epoch  1, loss  1.9256, train acc  0.301, test acc  0.570, time  1714.7 sec\n",
      "epoch  1, loss  1.9219, train acc  0.302, test acc  0.571, time  1716.6 sec\n",
      "epoch  1, loss  1.9184, train acc  0.303, test acc  0.571, time  1718.4 sec\n",
      "epoch  1, loss  1.9147, train acc  0.304, test acc  0.570, time  1720.2 sec\n",
      "epoch  1, loss  1.9113, train acc  0.306, test acc  0.570, time  1722.0 sec\n",
      "epoch  1, loss  1.9076, train acc  0.307, test acc  0.570, time  1723.8 sec\n",
      "epoch  1, loss  1.9039, train acc  0.308, test acc  0.572, time  1725.7 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1, loss  1.9008, train acc  0.309, test acc  0.578, time  1727.5 sec\n",
      "epoch  1, loss  1.8973, train acc  0.310, test acc  0.580, time  1729.3 sec\n",
      "epoch  1, loss  1.8941, train acc  0.311, test acc  0.575, time  1731.1 sec\n",
      "epoch  1, loss  1.8905, train acc  0.312, test acc  0.572, time  1732.9 sec\n",
      "epoch  1, loss  1.8873, train acc  0.313, test acc  0.570, time  1734.7 sec\n",
      "epoch  1, loss  1.8840, train acc  0.314, test acc  0.568, time  1736.5 sec\n",
      "epoch  1, loss  1.8804, train acc  0.316, test acc  0.565, time  1738.3 sec\n",
      "epoch  1, loss  1.8768, train acc  0.317, test acc  0.563, time  1740.3 sec\n",
      "epoch  1, loss  1.8734, train acc  0.318, test acc  0.564, time  1742.1 sec\n",
      "epoch  1, loss  1.8701, train acc  0.319, test acc  0.564, time  1744.1 sec\n",
      "epoch  1, loss  1.8668, train acc  0.320, test acc  0.566, time  1746.2 sec\n",
      "epoch  1, loss  1.8638, train acc  0.321, test acc  0.569, time  1748.4 sec\n",
      "epoch  1, loss  1.8605, train acc  0.322, test acc  0.574, time  1750.4 sec\n",
      "epoch  1, loss  1.8572, train acc  0.323, test acc  0.579, time  1752.3 sec\n",
      "epoch  1, loss  1.8542, train acc  0.324, test acc  0.582, time  1754.4 sec\n",
      "epoch  1, loss  1.8512, train acc  0.325, test acc  0.585, time  1756.2 sec\n",
      "epoch  1, loss  1.8483, train acc  0.326, test acc  0.590, time  1758.1 sec\n",
      "epoch  1, loss  1.8457, train acc  0.327, test acc  0.594, time  1760.2 sec\n",
      "epoch  2, loss  0.0046, train acc  0.582, test acc  0.596, time  1.9 sec\n",
      "epoch  2, loss  0.0092, train acc  0.602, test acc  0.596, time  3.8 sec\n",
      "epoch  2, loss  0.0138, train acc  0.589, test acc  0.595, time  5.7 sec\n",
      "epoch  2, loss  0.0184, train acc  0.587, test acc  0.594, time  7.5 sec\n",
      "epoch  2, loss  0.0229, train acc  0.595, test acc  0.594, time  9.3 sec\n",
      "epoch  2, loss  0.0274, train acc  0.598, test acc  0.593, time  11.1 sec\n",
      "epoch  2, loss  0.0318, train acc  0.597, test acc  0.592, time  13.0 sec\n",
      "epoch  2, loss  0.0361, train acc  0.595, test acc  0.593, time  14.8 sec\n",
      "epoch  2, loss  0.0403, train acc  0.600, test acc  0.595, time  16.6 sec\n",
      "epoch  2, loss  0.0444, train acc  0.598, test acc  0.594, time  18.4 sec\n",
      "epoch  2, loss  0.0486, train acc  0.600, test acc  0.592, time  20.2 sec\n",
      "epoch  2, loss  0.0526, train acc  0.600, test acc  0.590, time  22.0 sec\n",
      "epoch  2, loss  0.0567, train acc  0.600, test acc  0.588, time  23.8 sec\n",
      "epoch  2, loss  0.0609, train acc  0.596, test acc  0.586, time  25.8 sec\n",
      "epoch  2, loss  0.0649, train acc  0.598, test acc  0.586, time  27.8 sec\n",
      "epoch  2, loss  0.0688, train acc  0.598, test acc  0.587, time  29.7 sec\n",
      "epoch  2, loss  0.0725, train acc  0.604, test acc  0.585, time  31.7 sec\n",
      "epoch  2, loss  0.0765, train acc  0.603, test acc  0.588, time  33.6 sec\n",
      "epoch  2, loss  0.0801, train acc  0.605, test acc  0.590, time  35.6 sec\n",
      "epoch  2, loss  0.0841, train acc  0.602, test acc  0.592, time  37.7 sec\n",
      "epoch  2, loss  0.0879, train acc  0.601, test acc  0.595, time  39.8 sec\n",
      "epoch  2, loss  0.0916, train acc  0.602, test acc  0.599, time  42.0 sec\n",
      "epoch  2, loss  0.0955, train acc  0.600, test acc  0.602, time  43.9 sec\n",
      "epoch  2, loss  0.0989, train acc  0.600, test acc  0.604, time  45.9 sec\n",
      "epoch  2, loss  0.1026, train acc  0.600, test acc  0.614, time  47.7 sec\n",
      "epoch  2, loss  0.1061, train acc  0.602, test acc  0.613, time  49.5 sec\n",
      "epoch  2, loss  0.1098, train acc  0.601, test acc  0.611, time  51.3 sec\n",
      "epoch  2, loss  0.1134, train acc  0.601, test acc  0.609, time  53.1 sec\n",
      "epoch  2, loss  0.1169, train acc  0.600, test acc  0.611, time  55.0 sec\n",
      "epoch  2, loss  0.1203, train acc  0.601, test acc  0.616, time  56.8 sec\n",
      "epoch  2, loss  0.1237, train acc  0.602, test acc  0.618, time  59.0 sec\n",
      "epoch  2, loss  0.1272, train acc  0.602, test acc  0.612, time  61.2 sec\n",
      "epoch  2, loss  0.1306, train acc  0.601, test acc  0.611, time  63.1 sec\n",
      "epoch  2, loss  0.1338, train acc  0.602, test acc  0.611, time  65.0 sec\n",
      "epoch  2, loss  0.1371, train acc  0.603, test acc  0.608, time  67.0 sec\n",
      "epoch  2, loss  0.1405, train acc  0.602, test acc  0.607, time  69.0 sec\n",
      "epoch  2, loss  0.1440, train acc  0.603, test acc  0.607, time  71.0 sec\n",
      "epoch  2, loss  0.1474, train acc  0.601, test acc  0.608, time  72.9 sec\n",
      "epoch  2, loss  0.1507, train acc  0.601, test acc  0.608, time  74.9 sec\n",
      "epoch  2, loss  0.1540, train acc  0.600, test acc  0.610, time  76.9 sec\n",
      "epoch  2, loss  0.1572, train acc  0.602, test acc  0.609, time  78.9 sec\n",
      "epoch  2, loss  0.1602, train acc  0.603, test acc  0.608, time  80.9 sec\n",
      "epoch  2, loss  0.1634, train acc  0.604, test acc  0.606, time  82.9 sec\n",
      "epoch  2, loss  0.1665, train acc  0.604, test acc  0.607, time  84.9 sec\n",
      "epoch  2, loss  0.1697, train acc  0.603, test acc  0.608, time  86.7 sec\n",
      "epoch  2, loss  0.1728, train acc  0.603, test acc  0.609, time  88.7 sec\n",
      "epoch  2, loss  0.1760, train acc  0.602, test acc  0.609, time  90.8 sec\n",
      "epoch  2, loss  0.1790, train acc  0.602, test acc  0.612, time  92.8 sec\n",
      "epoch  2, loss  0.1822, train acc  0.601, test acc  0.614, time  94.9 sec\n",
      "epoch  2, loss  0.1848, train acc  0.600, test acc  0.616, time  97.0 sec\n",
      "epoch  2, loss  0.1877, train acc  0.600, test acc  0.617, time  99.2 sec\n",
      "epoch  2, loss  0.1906, train acc  0.601, test acc  0.618, time  101.2 sec\n",
      "epoch  2, loss  0.1931, train acc  0.601, test acc  0.625, time  103.1 sec\n",
      "epoch  2, loss  0.1960, train acc  0.601, test acc  0.623, time  105.2 sec\n",
      "epoch  2, loss  0.1989, train acc  0.600, test acc  0.617, time  107.2 sec\n",
      "epoch  2, loss  0.2016, train acc  0.601, test acc  0.615, time  109.0 sec\n",
      "epoch  2, loss  0.2048, train acc  0.600, test acc  0.616, time  111.0 sec\n",
      "epoch  2, loss  0.2076, train acc  0.600, test acc  0.615, time  113.0 sec\n",
      "epoch  2, loss  0.2103, train acc  0.600, test acc  0.615, time  114.9 sec\n",
      "epoch  2, loss  0.2131, train acc  0.600, test acc  0.616, time  116.9 sec\n",
      "epoch  2, loss  0.2159, train acc  0.600, test acc  0.618, time  118.9 sec\n",
      "epoch  2, loss  0.2183, train acc  0.601, test acc  0.622, time  121.0 sec\n",
      "epoch  2, loss  0.2211, train acc  0.601, test acc  0.621, time  123.1 sec\n",
      "epoch  2, loss  0.2240, train acc  0.600, test acc  0.622, time  125.1 sec\n",
      "epoch  2, loss  0.2264, train acc  0.600, test acc  0.620, time  127.1 sec\n",
      "epoch  2, loss  0.2288, train acc  0.600, test acc  0.628, time  129.0 sec\n",
      "epoch  2, loss  0.2313, train acc  0.600, test acc  0.621, time  131.2 sec\n",
      "epoch  2, loss  0.2336, train acc  0.601, test acc  0.618, time  133.3 sec\n",
      "epoch  2, loss  0.2361, train acc  0.601, test acc  0.618, time  135.2 sec\n",
      "epoch  2, loss  0.2384, train acc  0.601, test acc  0.617, time  137.4 sec\n",
      "epoch  2, loss  0.2408, train acc  0.601, test acc  0.616, time  139.2 sec\n",
      "epoch  2, loss  0.2433, train acc  0.601, test acc  0.618, time  141.0 sec\n",
      "epoch  2, loss  0.2456, train acc  0.601, test acc  0.620, time  142.9 sec\n",
      "epoch  2, loss  0.2479, train acc  0.601, test acc  0.621, time  144.7 sec\n",
      "epoch  2, loss  0.2502, train acc  0.601, test acc  0.624, time  146.5 sec\n",
      "epoch  2, loss  0.2524, train acc  0.602, test acc  0.626, time  148.3 sec\n",
      "epoch  2, loss  0.2544, train acc  0.603, test acc  0.629, time  150.2 sec\n",
      "epoch  2, loss  0.2567, train acc  0.603, test acc  0.632, time  152.0 sec\n",
      "epoch  2, loss  0.2590, train acc  0.603, test acc  0.633, time  154.0 sec\n",
      "epoch  2, loss  0.2611, train acc  0.604, test acc  0.635, time  155.8 sec\n",
      "epoch  2, loss  0.2634, train acc  0.604, test acc  0.639, time  157.6 sec\n",
      "epoch  2, loss  0.2654, train acc  0.605, test acc  0.641, time  159.5 sec\n",
      "epoch  2, loss  0.2677, train acc  0.605, test acc  0.651, time  161.3 sec\n",
      "epoch  2, loss  0.2702, train acc  0.605, test acc  0.645, time  163.2 sec\n",
      "epoch  2, loss  0.2723, train acc  0.606, test acc  0.641, time  165.3 sec\n",
      "epoch  2, loss  0.2744, train acc  0.606, test acc  0.641, time  167.2 sec\n",
      "epoch  2, loss  0.2766, train acc  0.607, test acc  0.639, time  169.1 sec\n",
      "epoch  2, loss  0.2788, train acc  0.607, test acc  0.639, time  171.0 sec\n",
      "epoch  2, loss  0.2809, train acc  0.607, test acc  0.642, time  172.8 sec\n",
      "epoch  2, loss  0.2829, train acc  0.608, test acc  0.642, time  174.7 sec\n",
      "epoch  2, loss  0.2848, train acc  0.608, test acc  0.644, time  176.8 sec\n",
      "epoch  2, loss  0.2869, train acc  0.608, test acc  0.658, time  178.8 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2, loss  0.2893, train acc  0.608, test acc  0.658, time  180.7 sec\n",
      "epoch  2, loss  0.2913, train acc  0.608, test acc  0.653, time  182.7 sec\n",
      "epoch  2, loss  0.2934, train acc  0.608, test acc  0.646, time  184.7 sec\n",
      "epoch  2, loss  0.2954, train acc  0.609, test acc  0.641, time  186.9 sec\n",
      "epoch  2, loss  0.2974, train acc  0.609, test acc  0.639, time  189.0 sec\n",
      "epoch  2, loss  0.2990, train acc  0.610, test acc  0.638, time  191.1 sec\n",
      "epoch  2, loss  0.3010, train acc  0.611, test acc  0.634, time  192.9 sec\n",
      "epoch  2, loss  0.3032, train acc  0.611, test acc  0.633, time  194.8 sec\n",
      "epoch  2, loss  0.3052, train acc  0.611, test acc  0.634, time  196.6 sec\n",
      "epoch  2, loss  0.3069, train acc  0.611, test acc  0.636, time  198.6 sec\n",
      "epoch  2, loss  0.3087, train acc  0.612, test acc  0.640, time  200.4 sec\n",
      "epoch  2, loss  0.3106, train acc  0.612, test acc  0.643, time  202.2 sec\n",
      "epoch  2, loss  0.3121, train acc  0.613, test acc  0.644, time  204.1 sec\n",
      "epoch  2, loss  0.3140, train acc  0.613, test acc  0.646, time  206.6 sec\n",
      "epoch  2, loss  0.3159, train acc  0.614, test acc  0.647, time  208.9 sec\n",
      "epoch  2, loss  0.3177, train acc  0.614, test acc  0.649, time  211.0 sec\n",
      "epoch  2, loss  0.3194, train acc  0.614, test acc  0.650, time  213.0 sec\n",
      "epoch  2, loss  0.3213, train acc  0.614, test acc  0.649, time  214.9 sec\n",
      "epoch  2, loss  0.3230, train acc  0.615, test acc  0.649, time  216.7 sec\n",
      "epoch  2, loss  0.3245, train acc  0.615, test acc  0.647, time  218.5 sec\n",
      "epoch  2, loss  0.3262, train acc  0.616, test acc  0.643, time  220.3 sec\n",
      "epoch  2, loss  0.3279, train acc  0.616, test acc  0.642, time  222.1 sec\n",
      "epoch  2, loss  0.3298, train acc  0.616, test acc  0.644, time  224.0 sec\n",
      "epoch  2, loss  0.3313, train acc  0.617, test acc  0.648, time  226.0 sec\n",
      "epoch  2, loss  0.3331, train acc  0.617, test acc  0.651, time  228.0 sec\n",
      "epoch  2, loss  0.3349, train acc  0.616, test acc  0.653, time  230.0 sec\n",
      "epoch  2, loss  0.3364, train acc  0.617, test acc  0.654, time  232.1 sec\n",
      "epoch  2, loss  0.3380, train acc  0.617, test acc  0.655, time  234.0 sec\n",
      "epoch  2, loss  0.3396, train acc  0.618, test acc  0.652, time  236.0 sec\n",
      "epoch  2, loss  0.3411, train acc  0.618, test acc  0.651, time  238.2 sec\n",
      "epoch  2, loss  0.3429, train acc  0.618, test acc  0.648, time  240.2 sec\n",
      "epoch  2, loss  0.3447, train acc  0.618, test acc  0.647, time  242.1 sec\n",
      "epoch  2, loss  0.3461, train acc  0.619, test acc  0.647, time  244.3 sec\n",
      "epoch  2, loss  0.3475, train acc  0.620, test acc  0.644, time  246.2 sec\n",
      "epoch  2, loss  0.3492, train acc  0.620, test acc  0.641, time  248.0 sec\n",
      "epoch  2, loss  0.3506, train acc  0.620, test acc  0.641, time  249.8 sec\n",
      "epoch  2, loss  0.3521, train acc  0.620, test acc  0.639, time  251.6 sec\n",
      "epoch  2, loss  0.3538, train acc  0.620, test acc  0.640, time  253.6 sec\n",
      "epoch  2, loss  0.3553, train acc  0.620, test acc  0.642, time  255.5 sec\n",
      "epoch  2, loss  0.3567, train acc  0.621, test acc  0.646, time  257.4 sec\n",
      "epoch  2, loss  0.3582, train acc  0.621, test acc  0.650, time  259.5 sec\n",
      "epoch  2, loss  0.3597, train acc  0.621, test acc  0.656, time  261.4 sec\n",
      "epoch  2, loss  0.3613, train acc  0.621, test acc  0.667, time  263.3 sec\n",
      "epoch  2, loss  0.3628, train acc  0.621, test acc  0.677, time  265.3 sec\n",
      "epoch  2, loss  0.3640, train acc  0.622, test acc  0.681, time  267.2 sec\n",
      "epoch  2, loss  0.3656, train acc  0.622, test acc  0.681, time  269.1 sec\n",
      "epoch  2, loss  0.3673, train acc  0.622, test acc  0.682, time  270.9 sec\n",
      "epoch  2, loss  0.3688, train acc  0.622, test acc  0.681, time  272.7 sec\n",
      "epoch  2, loss  0.3701, train acc  0.623, test acc  0.678, time  274.7 sec\n",
      "epoch  2, loss  0.3715, train acc  0.623, test acc  0.676, time  276.6 sec\n",
      "epoch  2, loss  0.3729, train acc  0.624, test acc  0.673, time  278.7 sec\n",
      "epoch  2, loss  0.3742, train acc  0.624, test acc  0.671, time  280.8 sec\n",
      "epoch  2, loss  0.3756, train acc  0.624, test acc  0.669, time  282.6 sec\n",
      "epoch  2, loss  0.3768, train acc  0.625, test acc  0.664, time  284.8 sec\n",
      "epoch  2, loss  0.3782, train acc  0.625, test acc  0.662, time  286.9 sec\n",
      "epoch  2, loss  0.3794, train acc  0.626, test acc  0.662, time  288.8 sec\n",
      "epoch  2, loss  0.3807, train acc  0.626, test acc  0.665, time  290.8 sec\n",
      "epoch  2, loss  0.3818, train acc  0.626, test acc  0.668, time  292.9 sec\n",
      "epoch  2, loss  0.3831, train acc  0.627, test acc  0.669, time  294.8 sec\n",
      "epoch  2, loss  0.3843, train acc  0.627, test acc  0.671, time  296.6 sec\n",
      "epoch  2, loss  0.3859, train acc  0.627, test acc  0.670, time  298.5 sec\n",
      "epoch  2, loss  0.3871, train acc  0.628, test acc  0.669, time  300.4 sec\n",
      "epoch  2, loss  0.3883, train acc  0.628, test acc  0.669, time  302.2 sec\n",
      "epoch  2, loss  0.3897, train acc  0.628, test acc  0.668, time  304.1 sec\n",
      "epoch  2, loss  0.3907, train acc  0.629, test acc  0.665, time  306.0 sec\n",
      "epoch  2, loss  0.3919, train acc  0.629, test acc  0.666, time  308.0 sec\n",
      "epoch  2, loss  0.3933, train acc  0.629, test acc  0.663, time  309.9 sec\n",
      "epoch  2, loss  0.3947, train acc  0.630, test acc  0.663, time  311.8 sec\n",
      "epoch  2, loss  0.3959, train acc  0.630, test acc  0.664, time  313.9 sec\n",
      "epoch  2, loss  0.3971, train acc  0.630, test acc  0.666, time  315.9 sec\n",
      "epoch  2, loss  0.3983, train acc  0.630, test acc  0.672, time  318.1 sec\n",
      "epoch  2, loss  0.3995, train acc  0.631, test acc  0.677, time  320.1 sec\n",
      "epoch  2, loss  0.4007, train acc  0.631, test acc  0.679, time  322.2 sec\n",
      "epoch  2, loss  0.4020, train acc  0.631, test acc  0.681, time  324.1 sec\n",
      "epoch  2, loss  0.4033, train acc  0.631, test acc  0.681, time  326.1 sec\n",
      "epoch  2, loss  0.4043, train acc  0.632, test acc  0.681, time  328.2 sec\n",
      "epoch  2, loss  0.4052, train acc  0.632, test acc  0.678, time  330.0 sec\n",
      "epoch  2, loss  0.4064, train acc  0.633, test acc  0.675, time  331.9 sec\n",
      "epoch  2, loss  0.4077, train acc  0.633, test acc  0.673, time  333.9 sec\n",
      "epoch  2, loss  0.4086, train acc  0.633, test acc  0.670, time  335.9 sec\n",
      "epoch  2, loss  0.4096, train acc  0.634, test acc  0.667, time  337.8 sec\n",
      "epoch  2, loss  0.4105, train acc  0.634, test acc  0.667, time  339.8 sec\n",
      "epoch  2, loss  0.4114, train acc  0.635, test acc  0.667, time  341.7 sec\n",
      "epoch  2, loss  0.4122, train acc  0.635, test acc  0.667, time  343.8 sec\n",
      "epoch  2, loss  0.4132, train acc  0.635, test acc  0.668, time  345.9 sec\n",
      "epoch  2, loss  0.4142, train acc  0.636, test acc  0.674, time  347.8 sec\n",
      "epoch  2, loss  0.4154, train acc  0.636, test acc  0.680, time  349.6 sec\n",
      "epoch  2, loss  0.4162, train acc  0.637, test acc  0.688, time  351.6 sec\n",
      "epoch  2, loss  0.4170, train acc  0.637, test acc  0.691, time  353.9 sec\n",
      "epoch  2, loss  0.4181, train acc  0.638, test acc  0.696, time  355.8 sec\n",
      "epoch  2, loss  0.4191, train acc  0.638, test acc  0.698, time  357.6 sec\n",
      "epoch  2, loss  0.4200, train acc  0.639, test acc  0.698, time  359.4 sec\n",
      "epoch  2, loss  0.4209, train acc  0.639, test acc  0.697, time  361.2 sec\n",
      "epoch  2, loss  0.4219, train acc  0.639, test acc  0.696, time  363.2 sec\n",
      "epoch  2, loss  0.4230, train acc  0.640, test acc  0.697, time  365.0 sec\n",
      "epoch  2, loss  0.4240, train acc  0.640, test acc  0.697, time  367.0 sec\n",
      "epoch  2, loss  0.4251, train acc  0.640, test acc  0.697, time  368.9 sec\n",
      "epoch  2, loss  0.4261, train acc  0.641, test acc  0.697, time  370.9 sec\n",
      "epoch  2, loss  0.4270, train acc  0.641, test acc  0.700, time  373.0 sec\n",
      "epoch  2, loss  0.4280, train acc  0.641, test acc  0.700, time  374.9 sec\n",
      "epoch  2, loss  0.4290, train acc  0.642, test acc  0.699, time  377.0 sec\n",
      "epoch  2, loss  0.4299, train acc  0.642, test acc  0.697, time  379.0 sec\n",
      "epoch  2, loss  0.4307, train acc  0.643, test acc  0.697, time  381.1 sec\n",
      "epoch  2, loss  0.4316, train acc  0.643, test acc  0.695, time  383.1 sec\n",
      "epoch  2, loss  0.4327, train acc  0.643, test acc  0.693, time  385.1 sec\n",
      "epoch  2, loss  0.4334, train acc  0.644, test acc  0.693, time  387.0 sec\n",
      "epoch  2, loss  0.4344, train acc  0.644, test acc  0.696, time  389.1 sec\n",
      "epoch  2, loss  0.4355, train acc  0.644, test acc  0.696, time  391.0 sec\n",
      "epoch  2, loss  0.4363, train acc  0.644, test acc  0.697, time  392.9 sec\n",
      "epoch  2, loss  0.4373, train acc  0.644, test acc  0.700, time  394.7 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2, loss  0.4381, train acc  0.645, test acc  0.701, time  396.5 sec\n",
      "epoch  2, loss  0.4393, train acc  0.645, test acc  0.700, time  398.3 sec\n",
      "epoch  2, loss  0.4400, train acc  0.645, test acc  0.699, time  400.1 sec\n",
      "epoch  2, loss  0.4409, train acc  0.646, test acc  0.698, time  401.9 sec\n",
      "epoch  2, loss  0.4420, train acc  0.646, test acc  0.697, time  403.8 sec\n",
      "epoch  2, loss  0.4426, train acc  0.647, test acc  0.697, time  405.8 sec\n",
      "epoch  2, loss  0.4435, train acc  0.647, test acc  0.694, time  407.6 sec\n",
      "epoch  2, loss  0.4445, train acc  0.647, test acc  0.692, time  409.4 sec\n",
      "epoch  2, loss  0.4452, train acc  0.647, test acc  0.689, time  411.2 sec\n",
      "epoch  2, loss  0.4462, train acc  0.647, test acc  0.688, time  413.0 sec\n",
      "epoch  2, loss  0.4472, train acc  0.647, test acc  0.689, time  414.9 sec\n",
      "epoch  2, loss  0.4480, train acc  0.647, test acc  0.691, time  416.7 sec\n",
      "epoch  2, loss  0.4486, train acc  0.648, test acc  0.692, time  418.9 sec\n",
      "epoch  2, loss  0.4496, train acc  0.648, test acc  0.694, time  420.9 sec\n",
      "epoch  2, loss  0.4504, train acc  0.648, test acc  0.695, time  423.1 sec\n",
      "epoch  2, loss  0.4512, train acc  0.648, test acc  0.698, time  425.0 sec\n",
      "epoch  2, loss  0.4521, train acc  0.648, test acc  0.700, time  426.8 sec\n",
      "epoch  2, loss  0.4528, train acc  0.649, test acc  0.704, time  428.7 sec\n",
      "epoch  2, loss  0.4536, train acc  0.649, test acc  0.706, time  430.5 sec\n",
      "epoch  2, loss  0.4542, train acc  0.649, test acc  0.705, time  432.3 sec\n",
      "epoch  2, loss  0.4550, train acc  0.650, test acc  0.705, time  434.1 sec\n",
      "epoch  2, loss  0.4558, train acc  0.650, test acc  0.704, time  436.0 sec\n",
      "epoch  2, loss  0.4567, train acc  0.650, test acc  0.706, time  437.8 sec\n",
      "epoch  2, loss  0.4574, train acc  0.650, test acc  0.706, time  439.6 sec\n",
      "epoch  2, loss  0.4581, train acc  0.651, test acc  0.709, time  441.4 sec\n",
      "epoch  2, loss  0.4587, train acc  0.651, test acc  0.709, time  443.2 sec\n",
      "epoch  2, loss  0.4596, train acc  0.651, test acc  0.709, time  445.1 sec\n",
      "epoch  2, loss  0.4603, train acc  0.652, test acc  0.710, time  446.9 sec\n",
      "epoch  2, loss  0.4611, train acc  0.652, test acc  0.711, time  448.8 sec\n",
      "epoch  2, loss  0.4619, train acc  0.652, test acc  0.711, time  450.7 sec\n",
      "epoch  2, loss  0.4625, train acc  0.652, test acc  0.710, time  452.5 sec\n",
      "epoch  2, loss  0.4636, train acc  0.652, test acc  0.704, time  454.4 sec\n",
      "epoch  2, loss  0.4642, train acc  0.653, test acc  0.703, time  456.2 sec\n",
      "epoch  3, loss  0.0018, train acc  0.688, test acc  0.701, time  2.0 sec\n",
      "epoch  3, loss  0.0035, train acc  0.701, test acc  0.701, time  4.1 sec\n",
      "epoch  3, loss  0.0052, train acc  0.698, test acc  0.703, time  6.0 sec\n",
      "epoch  3, loss  0.0068, train acc  0.708, test acc  0.706, time  7.9 sec\n",
      "epoch  3, loss  0.0085, train acc  0.703, test acc  0.707, time  10.0 sec\n",
      "epoch  3, loss  0.0101, train acc  0.707, test acc  0.707, time  12.1 sec\n",
      "epoch  3, loss  0.0117, train acc  0.705, test acc  0.705, time  14.2 sec\n",
      "epoch  3, loss  0.0135, train acc  0.705, test acc  0.704, time  16.4 sec\n",
      "epoch  3, loss  0.0151, train acc  0.706, test acc  0.701, time  18.2 sec\n",
      "epoch  3, loss  0.0169, train acc  0.704, test acc  0.701, time  20.0 sec\n",
      "epoch  3, loss  0.0184, train acc  0.705, test acc  0.698, time  21.8 sec\n",
      "epoch  3, loss  0.0198, train acc  0.710, test acc  0.696, time  23.7 sec\n",
      "epoch  3, loss  0.0215, train acc  0.711, test acc  0.696, time  25.8 sec\n",
      "epoch  3, loss  0.0231, train acc  0.711, test acc  0.696, time  27.7 sec\n",
      "epoch  3, loss  0.0247, train acc  0.710, test acc  0.696, time  29.5 sec\n",
      "epoch  3, loss  0.0263, train acc  0.709, test acc  0.697, time  31.3 sec\n",
      "epoch  3, loss  0.0278, train acc  0.707, test acc  0.699, time  33.3 sec\n",
      "epoch  3, loss  0.0295, train acc  0.708, test acc  0.703, time  35.4 sec\n",
      "epoch  3, loss  0.0311, train acc  0.707, test acc  0.705, time  37.4 sec\n",
      "epoch  3, loss  0.0327, train acc  0.707, test acc  0.708, time  39.3 sec\n",
      "epoch  3, loss  0.0343, train acc  0.707, test acc  0.712, time  41.3 sec\n",
      "epoch  3, loss  0.0358, train acc  0.708, test acc  0.713, time  43.2 sec\n",
      "epoch  3, loss  0.0373, train acc  0.711, test acc  0.714, time  45.1 sec\n",
      "epoch  3, loss  0.0389, train acc  0.711, test acc  0.714, time  47.2 sec\n",
      "epoch  3, loss  0.0404, train acc  0.711, test acc  0.713, time  49.2 sec\n",
      "epoch  3, loss  0.0420, train acc  0.711, test acc  0.712, time  51.2 sec\n",
      "epoch  3, loss  0.0436, train acc  0.711, test acc  0.712, time  53.1 sec\n",
      "epoch  3, loss  0.0451, train acc  0.711, test acc  0.709, time  55.1 sec\n",
      "epoch  3, loss  0.0467, train acc  0.710, test acc  0.709, time  57.1 sec\n",
      "epoch  3, loss  0.0483, train acc  0.710, test acc  0.710, time  59.3 sec\n",
      "epoch  3, loss  0.0499, train acc  0.710, test acc  0.710, time  61.4 sec\n",
      "epoch  3, loss  0.0513, train acc  0.711, test acc  0.710, time  63.2 sec\n",
      "epoch  3, loss  0.0527, train acc  0.711, test acc  0.710, time  65.1 sec\n",
      "epoch  3, loss  0.0541, train acc  0.711, test acc  0.712, time  67.0 sec\n",
      "epoch  3, loss  0.0554, train acc  0.712, test acc  0.713, time  69.1 sec\n",
      "epoch  3, loss  0.0568, train acc  0.713, test acc  0.714, time  71.0 sec\n",
      "epoch  3, loss  0.0581, train acc  0.714, test acc  0.716, time  72.8 sec\n",
      "epoch  3, loss  0.0597, train acc  0.713, test acc  0.717, time  74.7 sec\n",
      "epoch  3, loss  0.0610, train acc  0.714, test acc  0.718, time  76.5 sec\n",
      "epoch  3, loss  0.0626, train acc  0.713, test acc  0.717, time  78.7 sec\n",
      "epoch  3, loss  0.0641, train acc  0.713, test acc  0.716, time  80.6 sec\n",
      "epoch  3, loss  0.0652, train acc  0.715, test acc  0.715, time  82.7 sec\n",
      "epoch  3, loss  0.0667, train acc  0.713, test acc  0.714, time  85.0 sec\n",
      "epoch  3, loss  0.0682, train acc  0.713, test acc  0.713, time  87.0 sec\n",
      "epoch  3, loss  0.0694, train acc  0.714, test acc  0.712, time  89.0 sec\n",
      "epoch  3, loss  0.0707, train acc  0.715, test acc  0.714, time  90.9 sec\n",
      "epoch  3, loss  0.0720, train acc  0.715, test acc  0.713, time  92.9 sec\n",
      "epoch  3, loss  0.0733, train acc  0.715, test acc  0.712, time  95.0 sec\n",
      "epoch  3, loss  0.0747, train acc  0.715, test acc  0.712, time  97.0 sec\n",
      "epoch  3, loss  0.0759, train acc  0.716, test acc  0.714, time  99.1 sec\n",
      "epoch  3, loss  0.0771, train acc  0.716, test acc  0.714, time  101.1 sec\n",
      "epoch  3, loss  0.0781, train acc  0.717, test acc  0.715, time  103.5 sec\n",
      "epoch  3, loss  0.0795, train acc  0.717, test acc  0.714, time  105.3 sec\n",
      "epoch  3, loss  0.0809, train acc  0.716, test acc  0.713, time  107.2 sec\n",
      "epoch  3, loss  0.0823, train acc  0.715, test acc  0.714, time  109.2 sec\n",
      "epoch  3, loss  0.0837, train acc  0.715, test acc  0.714, time  111.2 sec\n",
      "epoch  3, loss  0.0851, train acc  0.715, test acc  0.713, time  113.4 sec\n",
      "epoch  3, loss  0.0863, train acc  0.715, test acc  0.713, time  115.4 sec\n",
      "epoch  3, loss  0.0877, train acc  0.716, test acc  0.713, time  117.2 sec\n",
      "epoch  3, loss  0.0890, train acc  0.715, test acc  0.710, time  119.1 sec\n",
      "epoch  3, loss  0.0905, train acc  0.715, test acc  0.709, time  121.0 sec\n",
      "epoch  3, loss  0.0916, train acc  0.716, test acc  0.709, time  122.8 sec\n",
      "epoch  3, loss  0.0927, train acc  0.716, test acc  0.712, time  124.7 sec\n",
      "epoch  3, loss  0.0941, train acc  0.716, test acc  0.715, time  126.6 sec\n",
      "epoch  3, loss  0.0955, train acc  0.716, test acc  0.715, time  128.4 sec\n",
      "epoch  3, loss  0.0966, train acc  0.716, test acc  0.715, time  130.3 sec\n",
      "epoch  3, loss  0.0978, train acc  0.717, test acc  0.717, time  132.1 sec\n",
      "epoch  3, loss  0.0991, train acc  0.717, test acc  0.719, time  133.9 sec\n",
      "epoch  3, loss  0.1004, train acc  0.716, test acc  0.716, time  135.8 sec\n",
      "epoch  3, loss  0.1017, train acc  0.716, test acc  0.714, time  137.9 sec\n",
      "epoch  3, loss  0.1029, train acc  0.717, test acc  0.711, time  139.8 sec\n",
      "epoch  3, loss  0.1041, train acc  0.717, test acc  0.711, time  141.7 sec\n",
      "epoch  3, loss  0.1053, train acc  0.717, test acc  0.712, time  143.6 sec\n",
      "epoch  3, loss  0.1065, train acc  0.718, test acc  0.712, time  145.5 sec\n",
      "epoch  3, loss  0.1077, train acc  0.717, test acc  0.712, time  147.4 sec\n",
      "epoch  3, loss  0.1090, train acc  0.717, test acc  0.712, time  149.2 sec\n",
      "epoch  3, loss  0.1102, train acc  0.717, test acc  0.712, time  151.2 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3, loss  0.1115, train acc  0.716, test acc  0.712, time  153.4 sec\n",
      "epoch  3, loss  0.1127, train acc  0.717, test acc  0.713, time  155.3 sec\n",
      "epoch  3, loss  0.1137, train acc  0.716, test acc  0.717, time  157.1 sec\n",
      "epoch  3, loss  0.1148, train acc  0.716, test acc  0.719, time  159.1 sec\n",
      "epoch  3, loss  0.1161, train acc  0.716, test acc  0.721, time  160.9 sec\n",
      "epoch  3, loss  0.1173, train acc  0.716, test acc  0.720, time  162.9 sec\n",
      "epoch  3, loss  0.1185, train acc  0.717, test acc  0.719, time  164.9 sec\n",
      "epoch  3, loss  0.1196, train acc  0.717, test acc  0.719, time  166.9 sec\n",
      "epoch  3, loss  0.1209, train acc  0.717, test acc  0.720, time  168.9 sec\n",
      "epoch  3, loss  0.1219, train acc  0.717, test acc  0.719, time  170.9 sec\n",
      "epoch  3, loss  0.1231, train acc  0.717, test acc  0.717, time  172.7 sec\n",
      "epoch  3, loss  0.1240, train acc  0.718, test acc  0.714, time  174.6 sec\n",
      "epoch  3, loss  0.1252, train acc  0.718, test acc  0.713, time  176.4 sec\n",
      "epoch  3, loss  0.1263, train acc  0.718, test acc  0.712, time  178.3 sec\n",
      "epoch  3, loss  0.1275, train acc  0.717, test acc  0.711, time  180.1 sec\n",
      "epoch  3, loss  0.1285, train acc  0.718, test acc  0.710, time  182.0 sec\n",
      "epoch  3, loss  0.1295, train acc  0.718, test acc  0.710, time  183.8 sec\n",
      "epoch  3, loss  0.1305, train acc  0.718, test acc  0.710, time  185.7 sec\n",
      "epoch  3, loss  0.1315, train acc  0.718, test acc  0.710, time  187.6 sec\n",
      "epoch  3, loss  0.1326, train acc  0.718, test acc  0.713, time  189.7 sec\n",
      "epoch  3, loss  0.1339, train acc  0.718, test acc  0.717, time  191.5 sec\n",
      "epoch  3, loss  0.1349, train acc  0.718, test acc  0.718, time  193.4 sec\n",
      "epoch  3, loss  0.1360, train acc  0.718, test acc  0.719, time  195.4 sec\n",
      "epoch  3, loss  0.1371, train acc  0.718, test acc  0.719, time  197.4 sec\n",
      "epoch  3, loss  0.1382, train acc  0.718, test acc  0.718, time  199.3 sec\n",
      "epoch  3, loss  0.1392, train acc  0.718, test acc  0.720, time  201.9 sec\n",
      "epoch  3, loss  0.1403, train acc  0.718, test acc  0.720, time  204.2 sec\n",
      "epoch  3, loss  0.1414, train acc  0.718, test acc  0.722, time  206.1 sec\n",
      "epoch  3, loss  0.1423, train acc  0.718, test acc  0.722, time  207.9 sec\n",
      "epoch  3, loss  0.1432, train acc  0.719, test acc  0.721, time  209.7 sec\n",
      "epoch  3, loss  0.1443, train acc  0.719, test acc  0.722, time  211.6 sec\n",
      "epoch  3, loss  0.1454, train acc  0.719, test acc  0.723, time  213.5 sec\n",
      "epoch  3, loss  0.1464, train acc  0.719, test acc  0.724, time  215.3 sec\n",
      "epoch  3, loss  0.1475, train acc  0.719, test acc  0.725, time  217.1 sec\n",
      "epoch  3, loss  0.1485, train acc  0.719, test acc  0.725, time  219.0 sec\n",
      "epoch  3, loss  0.1496, train acc  0.719, test acc  0.724, time  220.9 sec\n",
      "epoch  3, loss  0.1505, train acc  0.719, test acc  0.724, time  222.7 sec\n",
      "epoch  3, loss  0.1515, train acc  0.720, test acc  0.723, time  224.6 sec\n",
      "epoch  3, loss  0.1525, train acc  0.719, test acc  0.724, time  226.4 sec\n",
      "epoch  3, loss  0.1535, train acc  0.719, test acc  0.724, time  228.3 sec\n",
      "epoch  3, loss  0.1545, train acc  0.719, test acc  0.723, time  230.1 sec\n",
      "epoch  3, loss  0.1555, train acc  0.719, test acc  0.721, time  232.0 sec\n",
      "epoch  3, loss  0.1565, train acc  0.719, test acc  0.722, time  233.9 sec\n",
      "epoch  3, loss  0.1574, train acc  0.719, test acc  0.723, time  235.7 sec\n",
      "epoch  3, loss  0.1584, train acc  0.720, test acc  0.723, time  237.6 sec\n",
      "epoch  3, loss  0.1594, train acc  0.720, test acc  0.724, time  239.4 sec\n",
      "epoch  3, loss  0.1604, train acc  0.720, test acc  0.723, time  241.3 sec\n",
      "epoch  3, loss  0.1613, train acc  0.720, test acc  0.724, time  243.1 sec\n",
      "epoch  3, loss  0.1624, train acc  0.720, test acc  0.724, time  245.0 sec\n",
      "epoch  3, loss  0.1634, train acc  0.720, test acc  0.724, time  246.9 sec\n",
      "epoch  3, loss  0.1642, train acc  0.720, test acc  0.723, time  248.9 sec\n",
      "epoch  3, loss  0.1651, train acc  0.720, test acc  0.723, time  250.8 sec\n",
      "epoch  3, loss  0.1661, train acc  0.720, test acc  0.722, time  252.6 sec\n",
      "epoch  3, loss  0.1670, train acc  0.721, test acc  0.722, time  254.4 sec\n",
      "epoch  3, loss  0.1678, train acc  0.721, test acc  0.722, time  256.3 sec\n",
      "epoch  3, loss  0.1688, train acc  0.721, test acc  0.721, time  258.2 sec\n",
      "epoch  3, loss  0.1697, train acc  0.721, test acc  0.719, time  260.0 sec\n",
      "epoch  3, loss  0.1707, train acc  0.721, test acc  0.718, time  261.9 sec\n",
      "epoch  3, loss  0.1716, train acc  0.721, test acc  0.716, time  263.9 sec\n",
      "epoch  3, loss  0.1725, train acc  0.721, test acc  0.716, time  265.8 sec\n",
      "epoch  3, loss  0.1735, train acc  0.721, test acc  0.718, time  267.6 sec\n",
      "epoch  3, loss  0.1743, train acc  0.721, test acc  0.720, time  269.4 sec\n",
      "epoch  3, loss  0.1752, train acc  0.721, test acc  0.724, time  271.2 sec\n",
      "epoch  3, loss  0.1761, train acc  0.721, test acc  0.726, time  273.1 sec\n",
      "epoch  3, loss  0.1771, train acc  0.721, test acc  0.726, time  275.0 sec\n",
      "epoch  3, loss  0.1780, train acc  0.721, test acc  0.725, time  276.8 sec\n",
      "epoch  3, loss  0.1790, train acc  0.721, test acc  0.724, time  278.6 sec\n",
      "epoch  3, loss  0.1799, train acc  0.721, test acc  0.725, time  280.6 sec\n",
      "epoch  3, loss  0.1807, train acc  0.721, test acc  0.728, time  282.5 sec\n",
      "epoch  3, loss  0.1816, train acc  0.721, test acc  0.729, time  284.5 sec\n",
      "epoch  3, loss  0.1826, train acc  0.721, test acc  0.727, time  286.5 sec\n",
      "epoch  3, loss  0.1836, train acc  0.720, test acc  0.725, time  288.9 sec\n",
      "epoch  3, loss  0.1844, train acc  0.721, test acc  0.721, time  290.8 sec\n",
      "epoch  3, loss  0.1852, train acc  0.721, test acc  0.718, time  292.7 sec\n",
      "epoch  3, loss  0.1862, train acc  0.721, test acc  0.717, time  294.6 sec\n",
      "epoch  3, loss  0.1871, train acc  0.721, test acc  0.718, time  296.6 sec\n",
      "epoch  3, loss  0.1879, train acc  0.721, test acc  0.719, time  298.5 sec\n",
      "epoch  3, loss  0.1886, train acc  0.721, test acc  0.720, time  300.4 sec\n",
      "epoch  3, loss  0.1894, train acc  0.721, test acc  0.720, time  302.3 sec\n",
      "epoch  3, loss  0.1902, train acc  0.722, test acc  0.720, time  304.2 sec\n",
      "epoch  3, loss  0.1911, train acc  0.721, test acc  0.722, time  306.1 sec\n",
      "epoch  3, loss  0.1918, train acc  0.722, test acc  0.722, time  308.0 sec\n",
      "epoch  3, loss  0.1926, train acc  0.722, test acc  0.724, time  310.0 sec\n",
      "epoch  3, loss  0.1933, train acc  0.722, test acc  0.725, time  311.9 sec\n",
      "epoch  3, loss  0.1941, train acc  0.722, test acc  0.726, time  313.8 sec\n",
      "epoch  3, loss  0.1948, train acc  0.723, test acc  0.728, time  316.5 sec\n",
      "epoch  3, loss  0.1956, train acc  0.723, test acc  0.729, time  319.0 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-614fb4df9390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_cuda_cpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/ML/Machine-Learning/Notebook-Code/Pytorch Practice/d2lzh_pytorch.py\u001b[0m in \u001b[0;36mtrain_cuda_cpu\u001b[0;34m(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mbatch_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             print('epoch % d, loss % .4f, train acc % .3f, test acc % .3f, time % .1f sec' % (\n\u001b[1;32m    230\u001b[0m                 epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n",
      "\u001b[0;32m~/Documents/ML/Machine-Learning/Notebook-Code/Pytorch Practice/d2lzh_pytorch.py\u001b[0m in \u001b[0;36mevaluate_accuracy\u001b[0;34m(data_iter, net, device)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# 评估模式，会关闭dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0macc_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0;31m# 改回训练模式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ce66c7c61713>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# -1 表示除了将batch_size的留住，其他都平铺\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "device = 'cpu'\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "d2l.train_cuda_cpu(net, train_iter, test_iter, batch_size, optimizer, device,num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
